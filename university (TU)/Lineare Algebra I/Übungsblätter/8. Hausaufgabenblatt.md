***
#### Aufgabe 8.1

**i)**

`\begin{proof}`
Offensichtlich ist $A_{n} \subseteq S_{n}$, da $S_{n}$ per Definition alle Permutationen von $\{ 1,2,\ldots,n \}$, also auch alle geraden Permutationen, umfasst. Desweiteren gilt auch $\varnothing \neq A_{n}$, da laut Definition der symmetrischen Gruppe auch immer das neutrale Element, also die Identität $\operatorname{id}_{n}$ in der Menge $S_{n}$ enthalten ist. Die Identität mit 

$$
\operatorname{id}_{n} = [1,2,\ldots,n]
$$

hat offensichtlich keine Fehlstände, und es gilt $\operatorname{sgn}(\operatorname{id}_{n}) = (-1)^{0} = 1$. Damit ist $\operatorname{id}_{n} \in A_{n}$, und somit $A_{n} \neq \varnothing$.

Für Untergruppen muss desweiteren gezeigt werden, dass $\sigma \circ \hat{\sigma} \in A_{n}$ für alle $\sigma,\hat{\sigma} \in A_{n}$. Angenommen $\sigma,\hat{\sigma} \in A_{n}$ seien beliebig. Es gilt

$$
\tilde{\sigma} = \sigma \circ \hat{\sigma} = [\sigma(\hat{\sigma}(1)), \sigma(\hat{\sigma}(2)), \ldots , \sigma(\hat{\sigma}(n))]
$$

$\tilde{\sigma}$ ist als Permutation von $[1,2,\ldots,n]$ auch in $S_{n}$, es bleibt also zu zeigen, dass $\operatorname{sgn}(\tilde{\sigma}) = 1$ gilt, die Anzahl der Fehlstände also gerade ist.

Nach Satz $7.7$ ist

$$
\operatorname{sgn}(\tilde{\sigma}) = \operatorname{sgn}(\sigma \circ \hat{\sigma}) \underbrace{ = }_{ 7.7 } \operatorname{sgn}(\sigma) \cdot \operatorname{sgn}(\hat{\sigma}) = 1 \cdot 1 = 1
$$

Da $\sigma,\hat{\sigma} \in A_{n}$ beliebig gewählt waren, gilt somit für alle $\sigma, \hat{\sigma} \in A_{n}$ auch $\sigma \circ \hat{\sigma} \in A_{n}$. Final bleibt zu zeigen, dass ein $\sigma^{-1} \in A_{n}$ mit $\sigma^{-1}\sigma = \operatorname{id}_{n} = \sigma\sigma^{-1}$ für jedes $\sigma \in A_{n}$ existiert. Es ist klar, dass aufgrund dessen, dass $S_{n}$ eine Gruppe ist, ein $\sigma^{-1} \in S_{n}$ mit den gewünschten Eigenschaften für jedes $\sigma \in S_{n}$ existiert. Es muss also für beliebige $\sigma \in S_{n}$ gelten

$$
\sigma\sigma^{-1} = \operatorname{id}_{n}
$$

also auch wieder nach Satz $7.7$

$$
\operatorname{sgn}(\sigma\sigma^{-1}) = \operatorname{sgn}(\sigma) \cdot \operatorname{sgn}(\sigma^{-1}) \stackrel{!}{=} 1 = \operatorname{sgn}(\operatorname{id}_{n})
$$

und daher auch $\operatorname{sgn}(\sigma) = \operatorname{sgn}(\sigma^{-1})$. Ist $\operatorname{sgn}(\sigma) = 1$, also $\sigma \in A_{n}$, ist daher auch $\operatorname{sgn}(\sigma^{-1}) = 1$, und somit $\sigma^{-1} \in A_{n}$. Somit ist auch die dritte Eigenschaft einer Untergruppe erfüllt, und $A_{n}$ ist tatsächlich Untergruppe von $S_{n}$.

`\end{proof}`

<br> 

**ii)**

`\begin{proof}`
Da $\pi \in S_{n}$ ist, kann das Vorzeichen von $\pi$ entweder gerade oder ungerade sein. Es ist also eine Fallunterscheidung durchzuführen:

**1. Fall:** $\operatorname{sgn}(\pi) = 1$, und wie in **i)** gezeigt, somit auch $\operatorname{sgn}(\pi^{-1}) = 1$

Daraus folgt, dass nach Satz $7.7$ für das Vorzeichen von $\pi \circ \sigma \circ \pi^{-1}$ gilt

$$
\operatorname{sgn}(\pi \circ \sigma \circ \pi^{-1}) = \operatorname{sgn}(\pi) \cdot \operatorname{sgn}(\sigma) \cdot \operatorname{sgn}(\pi^{-1}) = 1 \cdot 1 \cdot 1 = 1,
$$

da $\sigma \in A_{n}$ und somit $\operatorname{sgn}(\sigma) = 1$ gelten muss. Somit ist $\pi \circ \sigma \circ \pi^{-1} \in A_{n}$.

**2. Fall:** $\operatorname{sgn}(\pi) = -1$, und somit analog auch $\operatorname{sgn}(\pi^{-1}) = -1$

Daraus folgt, dass nach Satz $7.7$ für das Vorzeichen von $\pi \circ \sigma \circ \pi^{-1}$ gilt

$$
\operatorname{sgn}(\pi \circ \sigma \circ \pi^{-1}) = \operatorname{sgn}(\pi) \cdot \operatorname{sgn}(\sigma) \cdot \operatorname{sgn}(\pi^{-1}) = -1 \cdot 1 \cdot (-1) = -1 \cdot (-1) = 1,
$$

Somit ist auch $\pi \circ \sigma \circ \pi^{-1} \in A_{n}$. Also ist $\pi \circ \sigma \circ \pi^{-1} \in A_{n}$ unabhängig von $\operatorname{sgn}(\pi)$.

`\end{proof}`
<br> 

***
#### Aufgabe 8.2

**i)**

`\begin{proof}`
Sei $\sigma_{1} = (i_{1},i_{2},\ldots,i_{r})$ und $\sigma_{2} = (i_{r},i_{r-1},\ldots,i_{2},i_{1})$. Desweiteren definieren wir

$$
I = \{ i_{1},i_{2},\ldots,i_{r} \}
$$

Nun kann also für ein beliebiges $j \in \{ 1,2,\ldots,n \}$ entweder $j \in I$ oder $j \notin I$ gelten. Desweiteren ist $j$ von der Form $j = i_{k}$. Führen wir eine Fallunterscheidung durch:

**1. Fall:** $j \notin I$

Per Definition gilt also $\sigma_{1}(j) = \sigma_{2}(j) = j$. Es gilt also auch $\sigma_{1}(\sigma_{2}(j)) = \sigma_{1}(j) = j$, und somit ist $j$ invers zu sich selbst.

**2. Fall:** $j \in I$

Es gilt also $\sigma_{1}(\sigma_{2}(j)) = \sigma_{1}(i_{k-1}) = i_{k} = j$ nach Definitionen von $\sigma_{1}$ und $\sigma_{2}$. Damit $\sigma_{2}$ das inverse Element zu $\sigma_{1}$ darstellt, muss

$$
\sigma_{1}(\sigma_{2}(j)) = j
$$

für alle $j \in \{ 1,2,\ldots,n \}$ gelten. Wie gezeigt, gilt dies für ein beliebiges $j$, unabhängig davon, ob $j \in I$ oder $j \notin I$. Somit ist $\sigma_{2} = \sigma_{1}^{-1}$ mit

$$
\sigma_{1}\sigma_{2} = \sigma_{1}\sigma_{1}^{-1} = \operatorname{id}_{n}
$$

Auf ein Beweis dessen, dass auch $\sigma_{1}^{-1}\sigma_{1} = \operatorname{id}_{n}$ gilt, kann nach Definition des inversen Elements verzichtet werden, dies folgt unmittelbar aus oben bewiesener Rechtsinversität.

`\end{proof}`

<br> 

**ii)**

`\begin{proof}`
Für zwei elementfremde Zykel, d.h. Zykel $\sigma_1=\left(i_1, \ldots, i_r\right) \in S_n$ und $\sigma_2=\left(j_1, \ldots, j_s\right) \in S_n$ $\operatorname{mit}\left\{i_1, \ldots, i_r\right\} \cap\left\{j_1, \ldots, j_s\right\}=\emptyset$, muss für Kommutativität gelten, dass

$$
\begin{aligned}
\sigma_1 \sigma_2 & =\left[\sigma_1\left(\sigma_2(1)\right), \sigma_1\left(\sigma_2(2)\right), \ldots, \sigma_1\left(\sigma_2(n)\right)\right] \\
& = \left[\sigma_2\left(\sigma_1(1)\right), \sigma_2\left(\sigma_1(2)\right), \ldots, \sigma_2\left(\sigma_1(n)\right)\right] \\
& =\sigma_2 \sigma_1
\end{aligned}
$$

Zu zeigen ist also $\sigma_{1}(\sigma_{2}(x)) = \sigma_{2}(\sigma_{1}(x))$ für alle $x \in \{ 1,2,\ldots,n \}$. Auch hier muss wieder zwischen dem Fall, bei dem $x$ vertauscht, oder dem Fall, bei dem $x$ an seiner ursprünglichen Position festgehalten wird, unterschieden werden.

**1. Fall:** $x \notin \{ i_{1},i_{2},\ldots,i_{r} \}, \; x \notin \{ j_{1},j_{2},\ldots,j_{s} \}$

Somit gilt $\sigma_{1}(\sigma_{2}(x)) = \sigma_{1}(x) = x$ und $\sigma_{2}(\sigma_{1}(x)) = \sigma_{2}(x) = x$ per Definition eines Zykels. Somit sind die Zykel in diesem Fall für alle $x \in \{ 1,2,\ldots,n \}$ kommutativ.

**2. Fall:** $x \in \sigma_{1}$, und somit aufgrund der Elementfremdheit auch $x \notin \sigma_{2}$

Aufgrund der Elementfremdheit gilt auch, dass $\sigma_{1}(x) \notin \sigma_{2}$, da $\sigma_{1}(x)$ wieder in $\sigma_{1}$ abbildet, und dessen Elemente allesamt nicht in $\sigma_{2}$ seien dürfen. Es gilt also

$$
\sigma_{1}(\sigma_{2}(x_{k})) = \sigma_{1}(x_{k}) = x_{k+1} = \sigma_{2}(x_{k+1}) = \sigma_{2}(\sigma_{1}(x_{k}))
$$

Damit sind $\sigma_{1}$ und $\sigma_{2}$ auch in diesem Fall kommutativ.

**3. Fall:** $x \in \sigma_{2}$, und somit aufgrund der Elementfremdheit auch $x \notin \sigma_{1}$

Aufgrund der Elementfremdheit gilt auch, dass $\sigma_{2}(x) \notin \sigma_{1}$, da ${} \sigma_{2}(x) {}$ wieder in ${} \sigma_{2} {}$ abbildet, und dessen Elemente allesamt nicht in $\sigma_{1}$ seien dürfen. Es gilt also

$$
\sigma_{1}(\sigma_{2}(x_{k})) = \sigma_{1}(x_{k+1}) = x_{k+1} = \sigma_{2}(x_{k}) = \sigma_{2}(\sigma_{1}(x_{k}))
$$

Damit sind $\sigma_{1}$ und $\sigma_{2}$ auch in diesem Fall kommutativ. Da $\sigma_{1} \circ \sigma_{2} = \sigma_{2} \circ \sigma_{1}$ somit in jedem Fall gilt, ist auch (ii) bewiesen.

`\end{proof}`

<br> 

**(iii)**

`\begin{proof}`
Wir wählen $i \in \{ i_{1},i_{2},\ldots,i_{r} \}$, daraus folgt $i \in \sigma_{1}$ mit $\sigma_{1}(i_{k}) = i_{k+1}$ für $k \in \{ 1,2,\ldots,r-1 \}$ und $\sigma_{1}(r) = 1$. Damit wissen wir, dass $\sigma_{1}(i_{1}) = i_{2}, \; \sigma_{1}(i_{2}) = i_{3},\; \ldots \;, \sigma_{1}(i_{r-1}) = i_{r}$ und $\sigma_{1}(i_{r}) = i_{1}$. Damit sind wir am Anfang und der erste Zykel ist $(i_{1},i_{2},\ldots,i_{r})$.

Nun wählen wir ein Element $j \in S_{n}$ mit $j \notin (i_{1},\ldots,i_{r})$. Es ist $j \in \{ j_{1},j_{2},\ldots,j_{r} \}$ also $j \in \sigma_{2}$ mit $\sigma_{2}(j_{k}) = j_{k+1}$ für $k \in \{ 1,2,\ldots,r-1 \}$ und $\sigma_{2}(j_{r}) = j_{1}$. Dann ist wieder $\sigma_{2}(j_{1}) = j_{2}, \; \sigma_{2}(j_{2}) = j_{3}, \; \ldots , \sigma_{2}(j_{r-1}) = j_{r}$ und $\sigma_{2}(j_{r}) = j_{1}$. Somit sind wir auch hier wieder beim ersten Element angekommen und es gilt $\sigma_{2} = (j_{1},j_{2},\ldots,j_{r})$.

Nun wählen wir ein Element $m \in S_{n}$ mit $m \notin (i_{1},i_{2},\ldots,i_{r})$ und $m \notin (j_{1},j_{2},\ldots,j_{r})$. Sei $m \in \sigma_{3}$ mit $\sigma_{3}(m_{k}) = m_{k+1}$ für $k \in \{ 1,2,\ldots,r-1 \}$ und $\sigma_{3}(m_{r}) = m_{1}$. Nun ist $\sigma_{3} = (m_{1},m_{2},\ldots,m_{r})$.

Als nächstes wählen wir das Element $l \in S_{n}$ mit $l \notin \{ i_{1},i_{2},\ldots,i_{r} \}, \; l \notin \{ j_{1},j_{2},\ldots,j_{r} \}, l \notin \{ m_{1},m_{2},\ldots,m_{r} \}$. Es sei $\sigma_{4}(l) = l$, somit besteht dieses Zykel aus nur einem Element und es gilt $\sigma_{4} = (l)$. Da die Permutation $\sigma = \sigma_{1} \circ \sigma_{2} \circ \ldots \circ \sigma_{l} \in S_{n}$ eine Dimension von $n$ hat, ist sie endlich.

Seien nun $\sigma_{1} \cup \sigma_{2} \cup \sigma_{3} U \sigma_{4} = S_{n}$, dann gibt es kein Element $y$ mehr, für das gilt $y \in S_{n}, \; y \notin \sigma_{1} \cup \sigma_{2} \cup \sigma_{3} \cup \sigma_{4}$. Somit besitzen die Zykel $\sigma_{1},\sigma_{2},\sigma_{3}$ und $\sigma_{4}$ alle Elemente der Permutation. Wir wissen nun, dass $S_{n}$ Elemente besitzt, die entweder in $\sigma_{1},\sigma_{2},\sigma_{3}$ oder in $\sigma_{4}$ liegen, da Permutationen bijektiv sind.

Daraus folgt $(i_{1},\ldots,i_{r}) \circ (j_{1},\ldots,j_{r}) \circ (m_{1},\ldots,m_{r}) \circ (l) = \sigma_{1} \circ \sigma_{2} \circ \sigma_{3} \circ \sigma_{4} = \sigma$.

Nun wollen wir noch beweisen, dass die Zerlegung einer Permutation in elementfremde Zykeln eindeutig bis auf die Reihenfolge ist. Wir betrachten nun ein beliebiges Element in $S_{n}$. Sei $l \in S_{n}$ und $l \in \sigma_{4}$ mit $\sigma_{4}(l) = l$. Sei $m \in S_{n}$ mit $m \in \sigma_{3}$ und sei $j \in \sigma_{2}$. Sei $i_{2} \in \sigma_{1}$, dann ist $\sigma_{1}(i_{2}) = i_{3}, \; \sigma_{1}(i_{3}) = i_{4}, \; \ldots, \sigma_{1}(i_{r}) = i_{1}$ und $\sigma_{1}(i_{1}) = i_{2}$. Somit haben wir erneut den Zykel $(i_{1},\ldots,i_{r})$ gefunden, nur dieses mal als $(i_{2},i_{3},\ldots,i_{r},i_{1})$. Nun verknüpfen wir $(l) \circ (m_{1},\ldots,m_{r}) \circ (j_{1},\ldots,j_{r}) \circ (i_{1},\ldots,i_{r}) = \sigma$.

Insgesamt haben wir bewiesen, dass die Verknüpfung aller elementfremden Zykel die Permutation ist, wobei die Reihenfolge egal ist, da elementfremde Zykel kommutieren, wie in ii) bewiesen.

`\end{proof}`

<br> 

***
#### Aufgabe 8.3

**i)**

`\begin{proof}`
Nach der Signaturformel von Leibnitz gilt

$$
\det(A) = \sum_{\sigma \in S_{n} }^{} \operatorname{sgn}(\sigma) \prod_{i = 1}^{n} a_{i, \sigma(i)} 
$$

Da $a_{ij} = b_{ij} = c_{ij}$ für alle $i,j$ mit $i \neq k$, gilt für $i \neq k$:

$$
\begin{align}
\det(A) & = \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \left( \prod_{i = 1}^{n} a_{i, \sigma(i)} \right) \cdot a_{k,\sigma(k)} \\
 & = \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \left( \prod_{i = 1}^{n} a_{i, \sigma(i)} \right) \cdot (\lambda b_{k,\sigma (k)} + \mu c_{k,\sigma(k)}) \\
 & = \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{i = 1}^{n} a_{i, \sigma(i)} \cdot \lambda b_{k,\sigma(k)} + \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{i = 1}^{n} a_{i, \sigma(i)} \cdot \mu c_{k,\sigma(k)} \\
\end{align}
$$

Nutzt man nun aus, dass $a_{ij} = b_{ij} = c_{ij}$ für $i \neq k$, so gilt

$$
\lambda \cdot \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{i = 1}^{n} b_{i, \sigma(i)} \cdot b_{k,\sigma(k)} + \mu \cdot \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{i = 1}^{n} c_{i, \sigma(i)} \cdot c_{k,\sigma(k)} = \lambda \cdot \det(B) + \mu \cdot \det(C)
$$

Somit gilt $\det(A) = \lambda \det(B) + \mu \det(C)$ gilt. Eine analoge Aussage lässt sich nun auch für Spalten finden:

Betrachten wir dafür transponierte Matrizen, so gilt nach Lemma $7.10^{(5)}$ 

$$ 
\det(A) = \det(A^{\mathrm{T}}).
$$

Bei Betrachtung der Spalten folgt nun $A^{\mathrm{T}} = [a_{ji}], \; B^{\mathrm{T}} = [b_{ji}], \; C^{\mathrm{T}} = [c_{ji}] \in R^{n,n}$. Für $k \in \{ 1,\ldots,n \}$ gelte $a_{ji} = b_{ji} = c_{ji}$ für alle $j,i$ mit $j \neq k$, sowie $a_{ki} = \lambda b_{ki} + \mu c_{ki}$ für alle $i$.

Der Beweis erfolgt nun analog und es gilt

$$
\det(A^{\mathrm{T}}) = \sum_{\sigma \in S_{n} }^{} \operatorname{sgn}(\sigma) \prod_{j = 1}^{n} a_{j, \sigma(j)} 
$$

Da $a_{ji} = b_{ji} = c_{ji}$ für alle $i,j$ mit $j \neq k$, gilt für $j \neq k$:

$$
\begin{align}
\det(A^{\mathrm{T}}) & = \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \left( \prod_{j = 1}^{n} a_{j, \sigma(j)} \right) \cdot a_{k,\sigma(k)} \\
 & = \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \left( \prod_{j = 1}^{n} a_{j, \sigma(j)} \right) \cdot (\lambda b_{k,\sigma (k)} + \mu c_{k,\sigma(k)}) \\
 & = \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{j = 1}^{n} a_{j, \sigma(j)} \cdot \lambda b_{k,\sigma(k)} + \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{j = 1}^{n} a_{j, \sigma(j)} \cdot \mu c_{k,\sigma(k)} \\
\end{align}
$$

Nutzt man nun aus, dass ${} a_{ji} = b_{ji} = c_{ji}$ für $j \neq k$, so gilt

$$
\lambda \cdot \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{j = 1}^{n} b_{j, \sigma(j)} \cdot b_{k,\sigma(k)} + \mu \cdot \sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{j = 1}^{n} c_{j, \sigma(j)} \cdot c_{k,\sigma(k)} = \lambda \cdot \det(B^{\mathrm{T}}) + \mu \cdot \det(C^{\mathrm{T}})
$$

Somit gilt auch $\det (A^{\mathrm{T}}) = \lambda \cdot \det(B^{\mathrm{T}}) + \mu \cdot \det(C^{\mathrm{T}})$.

`\end{proof}`

<br> 

**ii)**

Wir wollen nun quadratische Matrizen $D,E \in R^{n,n}$ finden, wobei $\det(D+E) \neq \det(D) + \det(E)$.

Sei $D \in R^{2,2}$ mit

$$
D =
\begin{bmatrix}
1 & 2 \\
0 & 0 
\end{bmatrix}
$$

Dann folgt nach Lemma $7.10^{(3)}$, dass $\det(D) = 0$, da $D$ eine Nullzeile hat. Sei $E \in R^{2,2}$ mit

$$
E =
\begin{bmatrix}
0 & 0 \\
3 & 4
\end{bmatrix}
$$

Analog gilt also auch $\det(E) = 0$. Nun berechnen wir

$$
D + E =
\begin{bmatrix}
1 + 0 & 2 + 0 \\
0 + 3 & 0 + 4
\end{bmatrix}
=
\begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix}
$$

Da $n = 2$ gilt, gilt $\det(D + E) = A_{11} \cdot A_{22} - A_{12} \cdot A_{21} = 4 - 6 = -2$. Somit ist $\det(D + E) = -2 \neq 0 = \det(D) + \det(E)$.

**iii)**

Wir wählen $A_{11} = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix} \in R^{2,2}$. Da $A_{11}$ eine Nullzeile (und auch eine Nullspalte) besitzt, ist $\det(A_{11}) = 0$ nach Lemma $7.10^{(3)}$.

Zudem wählen wir $A_{12} = \begin{bmatrix} 0 & 0 \\ 1 & 0 \end{bmatrix} \in R^{2,2}$. Analog folgt also auch $\det(A_{12}) = 0$. Desweiteren seien

$$
A_{21} =
\begin{bmatrix}
0 & 1 \\
0 & 0
\end{bmatrix}
\in R^{2,2}
\quad
\text{ und }
A_{22} =
\begin{bmatrix}
0 & 0 \\
0 & 1
\end{bmatrix}
\in R^{2,2}
$$

also gilt auch hier nach Lemma $7.10^{(3)}$, dass $\det(A_{21}) = \det(A_{22}) = 0$. Insgesamt wissen wir also, dass alle der gewählten Matrizen die Determinante Null haben. Nun setzen wir die Matrizen zusammen und erhalten

$$
A =
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1
\end{bmatrix}
\in R^{4,4}
$$

Vertauschen der zweiten mit der dritten Zeile liefert

$$
A =
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1
\end{bmatrix}
\stackrel{P_{23}}{\longrightarrow}
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{bmatrix}
$$

Nach Lemma $7.13$ gilt $\det(P_{ij} A) = -\det(A)$. Da $A$ nun die Einheitsmatrix ist, und diese die Determinante $\det(I_{n}) = 1$ besitzt, folgt $-\det(A) = -1$. Insgesamt folgt somit

$$
\det \left(\begin{bmatrix}
A_{11} & A_{12} \\
A_{21} & A_{22}
\end{bmatrix}\right) = -1 \neq 0 = 0^{2} - 0^{2} = \det(A_{11}) \cdot \det(A_{22}) - \det(A_{12}) \cdot \det(A_{21})
$$

***

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

<br> 

#### Aufgabe 8.4

Wir nutzen den Gauß-Algorithmus, um die Matrix $A$ in die obere Dreiecksform zu bringen:

$$
\begin{align}
A_{n} =
\begin{bmatrix}
1 & 1 & 1 & 1 & \ldots & 1 \\
1 & 2 & 2 & 2 & \ldots & 2 \\
1 & 2 & 3 & 3 & \ldots & 3 \\
1 & 2 & 3 & 4 & \ldots & 4 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
1 & 2 & 3 & 4 & \ldots & n-2 \\
1 & 2 & 3 & 4 & \ldots & n-1 \\
1 & 2 & 3 & 4 & \ldots & n
\end{bmatrix}
\stackrel{G_{n-1,n}(-1)}{\longrightarrow} & 
\begin{bmatrix}
1 & 1 & 1 & 1 & \ldots & 1 \\
1 & 2 & 2 & 2 & \ldots & 2 \\
1 & 2 & 3 & 3 & \ldots & 3 \\
1 & 2 & 3 & 4 & \ldots & 4 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
1 & 2 & 3 & 4 & \ldots & n-2 \\
1 & 2 & 3 & 4 & \ldots & n-1 \\
0 & 0 & 0 & 0 & \ldots & 1
\end{bmatrix} \\
\stackrel{G_{n-2,n-1}(-1)}{\longrightarrow} & 
\begin{bmatrix}
1 & 1 & 1 & 1 & \ldots & 1 \\
1 & 2 & 2 & 2 & \ldots & 2 \\
1 & 2 & 3 & 3 & \ldots & 3 \\
1 & 2 & 3 & 4 & \ldots & 4 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
1 & 2 & 3 & 4 & \ldots & n-2 \\
0 & 0 & 0 & 0 & \ldots & 1 \\
0 & 0 & 0 & 0 & \ldots & 1
\end{bmatrix} \\
\stackrel{G_{n-3,n-2}(-1)}{\longrightarrow} &
\ldots \\
\stackrel{G_{1,2}(-1)}{\longrightarrow} &
\begin{bmatrix}
1 & 1 & 1 & 1 & \ldots & 1 \\
0 & 1 & 1 & 1 & \ldots & 1 \\
0 & 0 & 1 & 1 & \ldots & 1 \\
0 & 0 & 0 & 1 & \ldots & 1 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
\end{align}
$$

Nun haben wir $A_{n}$ in eine obere Dreiecksform gebracht, wobei die Hauptdiagonale nur aus Einsen besteht. Nach Lemma $7.10^{(2)}$ gilt, dass wenn $A = [a_{ij}]$ eine obere oder untere Dreiecksmatrix ist, so ist auch

$$ 
\det(A) = \prod_{i = 1}^{n} a_{ii}.
$$

Damit folgt $\det(A_{n}) = 1^{n} = 1$ für alle $n \in \mathbb{N}$.

Zur Berechnung von $\det(B)$ benutzen wir erneut den Gauß-Algorithmus, um $B$ in eine obere Dreiecksform zu bringen:

$$
\begin{align}
B =
\begin{bmatrix}
x & 1 & 1 & 1 & \ldots & 1 & 1 \\
1 & x & 1 & 1 & \ldots & 1 & 1 \\
1 & 1 & x & 1 & \ldots & 1 & 1 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
1 & 1 & 1 & 1 & \ldots & x & 1 \\
1 & 1 & 1 & 1 & \ldots & 1 & x
\end{bmatrix}
\stackrel{G_{n-1,n}(-1)^{\mathrm{T}}}{\longrightarrow} & 
\begin{bmatrix}
x & 1 & 1 & 1 & \ldots & 1 & 1 \\
1 & x & 1 & 1 & \ldots & 1 & 1 \\
1 & 1 & x & 1 & \ldots & 1 & 1 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \ldots & x-1 & 1-x \\
1 & 1 & 1 & 1 & \ldots & 1 & x
\end{bmatrix} \\
\stackrel{G_{n-2,n}(-1)^{\mathrm{T}}}{\longrightarrow} &
 \ldots \\
\stackrel{G_{1,n}(-1)^{\mathrm{T}}}{\longrightarrow} &
\begin{bmatrix}
x-1 & 0 & 0 & 0 & \ldots & 0 & 1-x \\
0 & x-1 & 0 & 0 & \ldots & 0 & 1-x \\
0 & 0 & x-1 & 0 & \ldots & 0 & 1-x \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \ldots & x-1 & 1-x \\
1 & 1 & 1 & 1 & \ldots & 1 & x
\end{bmatrix} \\
\stackrel{G_{1,n}\left( -\frac{1}{x-1} \right)}{\longrightarrow} &
\begin{bmatrix}
x-1 & 0 & 0 & 0 & \ldots & 0 & 1-x \\
0 & x-1 & 0 & 0 & \ldots & 0 & 1-x \\
0 & 0 & x-1 & 0 & \ldots & 0 & 1-x \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \ldots & x-1 & 1-x \\
0 & 1 & 1 & 1 & \ldots & 1 & x+1
\end{bmatrix} \\
\stackrel{G_{2,n}\left( -\frac{1}{x-1} \right)}{\longrightarrow} &
\begin{bmatrix}
x-1 & 0 & 0 & 0 & \ldots & 0 & 1-x \\
0 & x-1 & 0 & 0 & \ldots & 0 & 1-x \\
0 & 0 & x-1 & 0 & \ldots & 0 & 1-x \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \ldots & x-1 & 1-x \\
0 & 0 & 1 & 1 & \ldots & 1 & x+2
\end{bmatrix} \\
\stackrel{G_{3,n}\left( -\frac{1}{x-1} \right)}{\longrightarrow} &
\ldots \\
\stackrel{G_{n-1,n}\left( -\frac{1}{x-1} \right)}{\longrightarrow} &
\begin{bmatrix}
x-1 & 0 & 0 & 0 & \ldots & 0 & 1-x \\
0 & x-1 & 0 & 0 & \ldots & 0 & 1-x \\
0 & 0 & x-1 & 0 & \ldots & 0 & 1-x \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \ldots & x-1 & 1-x \\
0 & 0 & 0 & 0 & \ldots & 0 & x+n
\end{bmatrix}
\end{align}
$$

Somit haben wir $B$ in eine obere Dreiecksform gebracht. Nun nutzen wir Lemma $7.10^{(2)}$ wieder aus, wonach $\det(B) = \prod_{i = 1}^{n}b_{ii}$ gilt. Damit folgt

$$
\det(B) = (x-1)^{n-1} \cdot (x+n-1)
$$

An dieser Stelle muss noch eine Fallunterscheidung durchgeführt werden:

1. Sei $x = 1$. Dann können wir nicht mit $-\frac{1}{x-1}$ multiplizieren, allerdings gilt für $x = 1$:

$$
B =
\begin{bmatrix}
1 & 1 & 1 & \ldots & 1 \\
1 & 1 & 1 & \ldots & 1 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & 1 & 1 & \ldots & 1
\end{bmatrix}
\in \mathbb{Q}^{n,n}
$$

Somit besteht die Matrix $B$ nur aus Einselementen. Hier muss nun eine weitere Fallunterscheidung durchgeführt werden:

- Sei $n = 1$, dann folgt $B = 1$ und $\det(B) = 1$
- Sei $n \geq 2$, dann gilt nach $7.10^{(4)}$. dass bei zwei gleichen Zeilen oder Spalten die Determinante Null ist. Da für $x = 1$ und $n \geq 2$ die Matrix $B$ nur aus Einselementen besteht, gilt somit $\det(B) = 0$

2. Sei $x \neq 1$. Dann können wir mit $-\frac{1}{x-1}$ multiplizieren, und $\det(B) = (x-1)^{n-1} \cdot (x+n-1)$ für alle $x \in \mathbb{Q} \setminus \{ 1 \}$ und $n \geq 2$. Für $n = 1$ ist $\det(B) = x$ für alle $x \in \mathbb{Q}$.

Insgesamt haben wir berechnet, dass $\det(B) = 1$ für $x = 1$ und $n = 1$, $\det(B) = 0$ für $x = 1$ und $n \geq 2$, $\det(B) = (x-1)^{n-1} \cdot (x+n-1)$ für $n \geq 2$ und für alle $x \in \mathbb{Q}$ und $\det(B) = x$ für $n = 1$ und alle $x \in \mathbb{Q}$.